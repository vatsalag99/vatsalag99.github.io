<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Vatsal Agarwal</title>

    <meta name="author" content="Vatsal Agarwal">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/png" href="images/umd_square.png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Vatsal Agarwal
                </p>
                <p>I am a third year Ph.D student in the department of  <a href="https://www.cs.umd.edu/">Computer Science</a> at the University of
                  Maryland <a href="https://umd.edu/">(UMD)</a>, advised by <a
                      href="https://www.cs.umd.edu/~abhinav/">Professor Abhinav Shrivastava</a>. My research lies at the intersection of computer vision and deep learning. 
                </p>

                <p> 
                  I completed my undergrad in Computer Science at the University of Maryland in 2022. During my undergrad, I worked as a research assistant at the 
                  <a href="https://clinicalcenter.nih.gov/">National Institutes of Health Clinical Center</a> to develop deep learning models for medical imaging. I also interned as a machine learning engineer at <a href="https://deephealth.com/">DeepHealth</a>. 
                </p>

                <p> In the past, I have been fortunate to have worked with
                  <a href="https://tangyoubao.github.io">Youbao Tang</a>, <a href="https://lotterlab.github.io/">Bill Lotter</a>,
                  <a href="https://irp.nih.gov/pi/ronald-summers">Ronald Summers</a>, 
                  <a href="https://profiles.stanford.edu/suhas-srinivasan">Suhas Srinivasan</a>.
                </p>

                <p style="text-align:center">
                  <a href="mailto:vatsalag99@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_Vatsal.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=DJRhPVgAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/vatsalag99/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am interested in developing computer vision models for multimodal understanding (e.g. MLLMs, open-vocabulary segmentation). I am also broadly interested in developing efficient attention methods that scale across various applications including image classification and human mesh recovery. 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



            <tr>
              <td style="padding:40px;width:25%;vertical-align:middle">
                  <img src="images/diffvlm_teaser.png" alt="maps" width="160"
                      style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                  <papertitle>Multimodal Understanding using Stable-Diffusion as a Task Aware Feature
                    Extractor</papertitle>
                  <br>
                  <strong>Vatsal Agarwal</strong>,
                  <a href="https://www.linkedin.com/in/gefenkohavi"> Gefen Kohavi </a>,
                  <a href="https://mgwillia.github.io/"> Matthew Gwilliam </a>,
                  <a href="https://scholar.google.com/citations?user=2dDfKwUAAAAJ&hl=en"> Eshan Verma </a>,
                  <a href="https://scholar.google.com/citations?user=zIXl1-QAAAAJ&hl=en"> Daniel Ulbricht </a>,
                  <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
                  <br>
                  <em> Under Review </em>
                  <br>
                      <a href="https://vatsalag99.github.io/mustafar/">Project Page</a> |<a
                        href="data/Mustafar_DiffVLM_cameraready.pdf">Paper</a>
                  <p>We explore the potential of text-to-image diffusion models as visual encoders for MLLMs. Specifically, wen pass a question to a pre-trained diffusion model to obtain 
                    question-aware features. 
                  </p>
              </td>
          </tr>
  

            <tr>
              <td style="padding:40px;width:25%;vertical-align:middle">
                  <img src="images/maps_teaser.png" alt="maps" width="160"
                      style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                  <papertitle>MAPS: Memory Augmented Panoptic Segmentation</papertitle>
                  <br>
                  <strong>Vatsal Agarwal</strong>,
                  <a href="https://www.cs.umd.edu/~sakshams/">Saksham Suri</a>, 
                  <a href="https://maxlikelihood.ai/">Max Ehrlich</a>,
                  <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
                  <br>
                  <em> Under Review </em>
                  <br>
                      <a href="data/MAPS_cameraready.pdf">Paper</a>
                  <p>Explore potential of VLM-generated neural memory for panoptic segmentation.</p>
              </td>
          </tr>
  
            
            <tr>
              <td style="padding:40px;width:25%;vertical-align:middle">
                  <img src="images/diffssl_teaser.png" alt="diff_ssl2" width="160"
                      style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                  <papertitle>Do Text-free Diffusion Models Learn Discriminative Visual Representations?</papertitle>
                  <br>
                  <a href="https://mgwillia.github.io/"> Matthew Gwilliam* </a>,
                  <a href="https://soumik-kanad.github.io/">Soumik Mukhopadhyay*</a>,
                  <strong>Vatsal Agarwal<sup>&#10013;</sup></strong>,
                <span>Yosuke
                      Yamaguchi<sup>&#10013;</sup></span>,
                  <a href="https://newundergrad-lb.cs.umd.edu/people/namithap">Namitha Padmanabhan</a>,
                  <a href="https://archana1998.github.io/">Archana Swaminathan</a>,
                  <a href="https://tianyizhou.github.io/">Tianyi Zhou</a>,
                  <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
                  <br>
                  <em> ECCV 2024 </em>
                  <br>
                  <a href="https://mgwillia.github.io/diffssl/">Project Page</a> |<a
                      href="https://arxiv.org/abs/2311.17921">Paper</a>
                  <p>Explore diffusion models as unified unsupervised image representation learning
                    models for many recognition tasks. Propose DifFormer and DifFeed, novel mechanisms for fusing diffusion features 
                for image classification.</p>
              </td>
          </tr>

          <tr>
              <td style="padding:40px;width:25%;vertical-align:middle">
                  <img src="images/diffssl_v1_teaser.png" alt="diff_ssl1" width="160"
                      style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                  <papertitle>Diffusion Models Beat GANs on Image Classification</papertitle>
                  <br>
                  <a href="https://mgwillia.github.io/"> Matthew Gwilliam* </a>,
                  <a href="https://soumik-kanad.github.io/">Soumik Mukhopadhyay*</a>,
                  <strong>Vatsal Agarwal</strong>,
                  <a href="https://newundergrad-lb.cs.umd.edu/people/namithap">Namitha Padmanabhan</a>,
                  <a href="https://archana1998.github.io/">Archana Swaminathan</a>,
                  <a href="https://tianyizhou.github.io/">Tianyi Zhou</a>,
                  <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
                  <br>
                  <em> preprint only </em>
                  <br>
                  <a href="https://mgwillia.github.io/diff-ssl/">Project Page</a> |<a
                      href="https://arxiv.org/abs/2307.08702">Paper</a>
                  <p>Show the possible utility of diffusion models as unified unsupervised image representation learners.</p>
              </td>
          </tr>	

          <tr>
            <td style="padding:40px;width:25%;vertical-align:middle">
                <img src="images/coarsemetro.png" alt="coarsemetro" width="160"
                    style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Coarse-to-Fine Human Mesh Recovery with Transformers</papertitle>
                <br>
                <strong>Vatsal Agarwal</strong>,
                <a href="https://mlevy2525.github.io/">Mara Levy</a>,
                <a href="https://maxlikelihood.ai/">Max Ehrlich</a>,
                <a href="https://tangyoubao.github.io/">Youbao Tang</a>,
                <a href="https://scholar.google.com/citations?user=hLCSti0AAAAJ&hl=en">Ning Zhang</a>,
                <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
                <br>
                <em> ECCV 2024 Workshop: Towards a Complete Analysis of People: Fine-Grained Understanding for Real-World Applications </em>
                <br>
                    <a href="data/CoarseMETRO_cameraready.pdf">Paper</a>
                <p>Build efficient Transformer design for non-parametric human mesh recovery with coarse-to-fine pipeline.</p>
            </td>
        </tr>


        <tr>
          <td style="padding:40px;width:25%;vertical-align:middle">
              <img src="images/isbi_teaser.png" alt="coarsemetro" width="160"
                  style="border-style: none">
          </td>
          <td width="75%" valign="middle">
              <papertitle>Weakly Supervised Lesion Co-segmentation on CT Scans</papertitle>
              <br>
              <!-- Vatsal Agarwal*, Youbao Tang*, Jing Xiao, Ronald M. Summers -->
              <strong>Vatsal Agarwal*</strong>,
              <a href="https://tangyoubao.github.io/">Youbao Tang*</a>,
              <a href="https://scholar.google.com/citations?user=mcBd8KUAAAAJ&hl=en&oi=sra">Jing Xiao</a>,
              <a href="https://irp.nih.gov/pi/ronald-summers">Ronald M. Summers</a>
              
              <br>
              <em> IEEE International Symposium on Biomedical Imaging (ISBI), 2020 </em>
              <br>
                  <a href="https://arxiv.org/abs/2001.09174">Paper</a>
              <p>Conducted thorough investigation on impact of different attention mechanisms for lesion segmentation.</p>
          </td>
      </tr>

      <tr>
        <td style="padding:40px;width:25%;vertical-align:middle">
            <img src="images/spie_teaser.png" alt="coarsemetro" width="160"
                style="border-style: none">
        </td>
        <td width="75%" valign="middle">
            <papertitle>Weakly-Supervised Lesion Segmentation on CT Scans using Co-Segmentation</papertitle>
            <br>
            <!-- Vatsal Agarwal*, Youbao Tang*, Jing Xiao, Ronald M. Summers -->
            <strong>Vatsal Agarwal*</strong>,
            <a href="https://tangyoubao.github.io/">Youbao Tang*</a>,
            <a href="https://scholar.google.com/citations?user=mcBd8KUAAAAJ&hl=en&oi=sra">Jing Xiao</a>,
            <a href="https://irp.nih.gov/pi/ronald-summers">Ronald M. Summers</a>
            
            <br>
            <em> SPIE Medical Imaging, 2020 </em>
            <br>
                <a href="https://arxiv.org/abs/2001.08590">Paper</a>
            <p>Developed attention-based co-segmentation model and applied it to task of lesion segmentation.</p>
        </td>
    </tr>



   

          </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
                <tr>


                    <!-- <td> -->


                    <!-- <heading>Service</heading>
</td>
</tr>
</tbody></table>
<table width="100%" align="center" border="0" cellpadding="20"><tbody>
<tr>
<td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
<td width="75%" valign="center">
  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair, CVPR 2021</a>
  <br><br>
  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
  <br><br>
  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
</td>
</tr>
<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
  <img src="images/cs188.jpg" alt="cs188">
</td>
<td width="75%" valign="center">
  <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
  <br>
  <br>
  <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
  <br>
  <br>
  <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
</td>
</tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://jonbarron.info/">Template credits</a>
                        </p>
                    </td>
                </tr>
            </tbody>
        </table>
    </td>
</tr>
</table>
</body>

</html>